# ğŸ“Š Status Projektu lbrxWhisper

**Data:** 2025-05-30  
**Etap:** Integracja i optymalizacja MLX Whisper

## ğŸ¯ Cel Projektu

Stworzenie natywnego pipeline'u MLX dla przetwarzania gÅ‚osu:
```
Audio â†’ Whisper ASR â†’ LLM â†’ TTS â†’ Audio
```

Wszystko zoptymalizowane pod Apple Silicon z wykorzystaniem MLX.

## âœ… Co JuÅ¼ DziaÅ‚a

### 1. **MLX Whisper ASR**
- âœ… Wszystkie modele MLX Whisper (tiny â†’ large-v3)
- âœ… Transkrypcja w jÄ™zyku polskim
- âœ… Optymalizacja parametrÃ³w zapobiegajÄ…ca powtÃ³rzeniom
- âœ… Kluczowy parametr: `condition_on_previous_text=False`

### 2. **Serwery API**
- âœ… **Batch Server** (port 8123)
  - REST API kompatybilne z OpenAI
  - Endpoint: `/v1/audio/transcriptions`
  - ObsÅ‚uga plikÃ³w audio przez multipart/form-data
  
- âœ… **Realtime Server** (port 8126)
  - WebSocket dla streamingu
  - ObsÅ‚uga base64 encoded audio chunks
  - Naprawiony bÅ‚Ä…d w `process_base64_audio()`

### 3. **Konfiguracja**
- âœ… Centralny plik konfiguracji (`whisper_config.py`)
- âœ… Presety dla rÃ³Å¼nych scenariuszy:
  - Polski zoptymalizowany
  - Polski wysokiej jakoÅ›ci
  - Polski szybki
  - Dla haÅ‚aÅ›liwego audio
- âœ… Interaktywny konfigurator TUI (`whisper_config_tui.py`)

### 4. **Batch Processing**
- âœ… Skrypt do masowej transkrypcji (`batch_transcribe_all.py`)
- âœ… ObsÅ‚uga wielu formatÃ³w (m4a, mp3, wav, flac, ogg, webm)
- âœ… Zapis wynikÃ³w do plikÃ³w tekstowych

### 5. **Dokumentacja**
- âœ… Instrukcja uÅ¼ycia API (`how_to_transcribe.md`)
- âœ… Analiza parametrÃ³w (`WHISPER_CONFIG_ANALYSIS.md`)
- âœ… PorÃ³wnanie whisper.cpp vs MLX Whisper

## ğŸš§ W Trakcie Rozwoju

### 1. **TTS (Text-to-Speech)**
- âš ï¸ **DIA TTS** - zainstalowane ale generuje ciszÄ™ (placeholder)
- âŒ **CSM-MLX** - multi-speaker, nie zainstalowane
- ğŸ”„ Konwersja modeli PyTorch â†’ MLX

### 2. **Integracja z LLM**
- ğŸ“ Planowane: LMStudio + Ollama
- ğŸ“ Model konwersacyjny (Qwen3)
- ğŸ“ Voice chat w czasie rzeczywistym

### 3. **Dashboard TUI**
- ğŸ“ Rich terminal UI z ratatui
- ğŸ“ Monitoring transkrypcji
- ğŸ“ ZarzÄ…dzanie konwersacjami

## âš ï¸ Znane Problemy

### 1. **JakoÅ›Ä‡ Transkrypcji**
- Problem: SÅ‚aba jakoÅ›Ä‡ dla jÄ™zyka polskiego
- Objawy: BÅ‚Ä™dy ortograficzne, gramatyczne
- RozwiÄ…zanie: Optymalizacja parametrÃ³w, lepsze prompty

### 2. **DIA TTS**
- Problem: Generuje tylko ciszÄ™
- Przyczyna: Placeholder implementation w `tts_servers/dia/mlx_model.py`
- Potrzebne: Rzeczywista implementacja generowania audio

### 3. **Format API**
- Problem: Format "text" nie zaimplementowany
- ObejÅ›cie: UÅ¼ywaÄ‡ tylko format "json"

## ğŸ› ï¸ Parametry Optymalizacji

### Kluczowe parametry dla polskiego:
```python
condition_on_previous_text=False  # NAJWAÅ»NIEJSZE! Zapobiega powtÃ³rzeniom
compression_ratio_threshold=2.4   # Wykrywa powtarzajÄ…cy siÄ™ tekst
language="pl"                     # Wymuszenie polskiego
initial_prompt="Transkrypcja rozmowy po polsku."
beam_size=5                       # Dla lepszej jakoÅ›ci
temperature=0.0                   # Deterministyczne
```

## ğŸ“ Struktura Projektu

```
lbrxWhisper/
â”œâ”€â”€ mlx_whisper/          # Core MLX Whisper
â”œâ”€â”€ whisper_servers/      # Serwery API (batch/realtime)
â”œâ”€â”€ tts_servers/          # Serwery TTS (DIA/CSM)
â”œâ”€â”€ whisper_config.py     # Centralna konfiguracja
â”œâ”€â”€ whisper_config_tui.py # Interaktywny konfigurator
â”œâ”€â”€ batch_transcribe_all.py # Batch processing
â”œâ”€â”€ outputs/              # Wyniki transkrypcji
â”‚   â”œâ”€â”€ txt/             # Auto-detect jÄ™zyka
â”‚   â””â”€â”€ txt_pl/          # Wymuszony polski
â””â”€â”€ uploads/             # Pliki do transkrypcji
```

## ğŸš€ NastÄ™pne Kroki

1. **Naprawa DIA TTS**
   - Implementacja rzeczywistego generowania audio
   - Testy z rÃ³Å¼nymi gÅ‚osami

2. **Instalacja CSM-MLX**
   - Multi-speaker synthesis
   - Lepsza jakoÅ›Ä‡ gÅ‚osu

3. **Integracja LLM**
   - PoÅ‚Ä…czenie z LMStudio/Ollama
   - Pipeline: ASR â†’ LLM â†’ TTS

4. **Dashboard TUI**
   - Monitoring w czasie rzeczywistym
   - ZarzÄ…dzanie sesjami

## ğŸ’¡ WskazÃ³wki

### Uruchomienie demo:
```bash
python lbrx_whisper_demo.py
```

### Szybka transkrypcja:
```bash
python batch_transcribe_all.py --language pl
```

### Konfiguracja interaktywna:
```bash
python whisper_config_tui.py
```

### Serwery w tle:
```bash
python start_servers.py &
```

## ğŸ“Š Metryki WydajnoÅ›ci

- **Czas transkrypcji:** ~15-20 min dla 59 plikÃ³w
- **Model:** whisper-large-v3-mlx (1.5B parametrÃ³w)
- **ZuÅ¼ycie RAM:** ~4-6 GB
- **Wykorzystanie GPU:** Metal Performance Shaders

## ğŸ¤ WspÃ³Å‚praca

Projekt rozwijany przez Macieja Gada z pomocÄ… Claude (Anthropic).
Wykorzystuje Apple MLX framework dla optymalnej wydajnoÅ›ci na Apple Silicon.

---

*Status na dzieÅ„: 2025-05-30*